% Generated by roxygen2 (4.1.1): do not edit by hand
% Please edit documentation in R/Utils.R
\name{Utils}
\alias{Cons.Vars}
\alias{CreateDummy}
\alias{Performance.measures}
\alias{Split}
\alias{SplitCrossVal}
\alias{Utils}
\alias{cbind.na}
\alias{collect.garbage}
\alias{data.frame.na}
\alias{get.bootResults}
\alias{get.cvResults}
\alias{get.para}
\alias{get.varimp}
\alias{normalize01}
\alias{opt_thresh}
\alias{rbind.na}
\title{Utility functions.}
\usage{
Split(Nt, K)

SplitCrossVal(D.dat, k, ix.cv, val.propo = 0.15)

collect.garbage()

CreateDummy(D.dat)

normalize01(x)

Cons.Vars(dummy, thresh = 0.00016, uniqueCut = 10)

opt_thresh(prob, obs)

Performance.measures(pred, obs, prevalence = NULL, threshold = NULL)

get.para(object, para)

get.cvResults(object)

get.bootResults(object, alpha = 0.05)

get.varimp(object, alpha = 0.05, top = 10)

cbind.na(..., deparse.level = 1)

rbind.na(..., deparse.level = 1)

data.frame.na(..., row.names = NULL, check.rows = FALSE,
  check.names = TRUE, stringsAsFactors = FALSE)
}
\arguments{
\item{Nt}{Sample size}

\item{K,k}{number of cross-validation and cross-validation number}

\item{D.dat,x}{A matix/data frame}

\item{ix.cv}{cross-validation indices}

\item{val.propo}{training set proportion}

\item{dummy}{numeric or factor variable}

\item{thresh}{threshold for deciding if variable is constant}

\item{uniqueCut}{minimum number of unique values for a variable to not be
considered as constant}

\item{prob,pred,obs}{predicted probabilities and true observed binary response vectors}

\item{threshold,prevalence}{classification threshold and observed class prevalence}

\item{object}{train cv or bootstrap models}

\item{para}{model hyper-parameters}

\item{alpha}{significance level}

\item{top}{top number of variables to return}

\item{deparse.level}{see \code{\link[base]{cbind}}}

\item{row.names,check.rows,check.names,stringsAsFactors}{= FALSE see \code{\link[base]{data.frame}}}

\item{\dots}{further arguments passed to or from other methods.}
}
\value{
training, validation, test data sets or K-fold cross-validation data sets.
}
\description{
Some useful miscellaneous functions
















}
\details{
\enumerate{
  \item \code{normalize01}: Normalize continuous attributes to [0,1]
  \item \code{Cons.Vars}: Detect binary variables with extreme imbalance in
class distribution
  \item \code{opt_thresh}: Wrapper for the function to compute optimal classification threshold
from the package \code{\link[PresenceAbsence]{PresenceAbsence}}
  \item \code{Performance.measures}: compute performance measures: AUC,
sensitivity, specificity, PPV, etc.
  \item \code{get.para}:
  Extract tuning parameters from cross-validation (RunCV) model with best performance
  \item \code{get.cvResults}: Extract cross-validation results: average
   performance measures over all cross-validations
\item \code{get.bootResults}: Extract bootstrap results: mean and confidence
intervals
\item \code{get.varimp}: Extract variable importance for GLM, GBM and RF models
}
}
\author{
Che Ngufor Ngufor.Che@mayo.edu
}

